
<div align="center">
  <img src="media/powerbi.png" alt="11" width="70%">
  <img src="media/dsa.png" alt="22" width="20%">
</div>

Este reposit√≥rio estrutura o conte√∫do da segunda metade do curso "Business Intelligence e Data Science" da Data Science Academy (~ 72horas de dura√ß√£o, n√≠vel intermedi√°rio) e inclui um portfolio de projetos constru√≠dos com base na segunda metade do mesmo curso.

### Qual o porqu√™ da separa√ß√£o?
A primeira metade do curso √© voltada para a funcionalidade do Power BI: visualiza√ß√µes, linguagem DAX e M, funcionalidades nativas, etc.
**J√° a segunda metade, observada neste reposit√≥rio, possui como foco:**
1. A integra√ß√£o do Power BI com Bancos de dados;
2. O uso de SQL Analytics neste contexto;
3. Aplica√ß√£o de t√©cnicas de _Machine Learning_ para segmenta√ß√£o e detec√ß√£o de anomalias, com o aux√≠lio de linguagens Python e R;
4. O uso de Intelig√™ncia Artificial para an√°lise de s√©ries temporais no Power BI; e
5. Um estudo de caso

A oportunidade √© fortuita para o aprendizado de algumas aplica√ß√µes acess√≥rias como ODBC e SQLite.

Em conjunto, estes exerc√≠cios come√ßam a integrar as diferentes ferramentas com as quais possuo familiaridade na √°rea de ci√™ncia de dados.

<br>

---

<h1 align="center">1. A integra√ß√£o do Power BI com Bancos de Dados</h1>

Embora eu esteja familiarizado com DBMS's como PostgreSQL/MySQL e suas respectivas utiliza√ß√µes em GUI's como pgAdmin4/MySQL Workbench, o projeto atual permite a intera√ß√£o com duas novas ferramentas cuja intera√ß√£o foge do par usual DMBS <--> Interface Gr√°fica:

- o **SQLite** √© um sistema de banco de dados leve e sem servidor.
  - Diferentemente do PostgreSQL/MySQL, o SQLite n√£o exige um servidor dedicado; o banco de dados √© apenas um √∫nico arquivo no disco.
  - Frequentemente usado em projetos pequenos, sistemas embarcados ou situa√ß√µes onde a simplicidade √© mais importante do que a escalabilidade. Comum, por exemplo, em aplica√ß√µes de smartphones.
  - O SQLite n√£o possui uma ferramenta GUI nativa como o pgAdmin4 ou MySQL Workbench, mas pode ser usado com ferramentas de terceiros como o DB Browser for SQLite ou DBeaver.

- O **ODBC (Open Database Connectivity)** √© uma API padronizada para acessar diferentes sistemas de banco de dados.
  - Ele funciona como uma ponte entre aplica√ß√µes e DBMS's, permitindo que interajam *independentemente* do tipo de banco de dados subjacente.
  - O ODBC **n√£o** √© um sistema de gerenciamento de banco de dados, mas um meio de conectar-se a um.
  - Ou seja, √© um intermedi√°rio que permite que diferentes aplica√ß√µes se comuniquem com bancos de dados. Ele n√£o √© diretamente compar√°vel aos pares mencionados acima, mas complementa o SQLite (ou qualquer banco de dados) ao fornecer uma maneira padronizada de se conectar a ele.

  ---

O ODBC Driver existe na vers√£o Trial, no momento de cria√ß√£o deste projeto, com licen√ßa de 30 dias. Devido ao prop√≥sito did√°tico do projeto, isto n√£o configura um problema.

<div align="center">
  <img src="media/a1.png" alt="a1">
</div>

<br>
A conex√£o √©, de fato, realiada da maneira mais sucinta poss√≠vel, seguindo o paradigma enxuto do SQLite. N√£o h√° servidor dedicado de hospedagem, a base de dados √© armazenada em um √∫nico arquivo em disco:

<br>

<div align="center">
  <img src="media/a2.png" alt="a2">
</div>

<br>

Ap√≥s a conex√£o com o SQLite e a ingest√£o dos dados, podemos utilizar instru√ß√µes SQL para realizar filtros ou gerar novas vistas. Algo como:
```
SELECT Nome_Produto,
        ROUND(MIN(Valor_Venda, 2) AS valor_m√≠nimo),
        ROUND(MAX(Valor_Venda, 2) AS valor_m√°ximo),
        ROUND(AVG(Valor_Venda, 2) AS valor_m√©dio),
        ROUND(SUM(Valor_Venda, 2) AS valor_total),
        COUNT(Valor_Venda) AS contagem,
        Ano
FROM TB_DSA_VENDAS, TB_DSA_PRODUTOS, TB_DSA_PEDIDOS,
WHERE TB_DSA_VENDAS.produto = TB_DSA_PRODUTOS.id_produto
AND TBD_DSA_VENDAS.pedido = TB_DSA_PEDIDOS.id_pedido
GROUP BY Produto, Ano
ORDER BY Contagem DESC
LIMIT 1000
```

Caso contr√°rio, as tabelas s√£o carregadas no ambiente do Power BI e seguimos com o tratamento padr√£o:

<br>

<div align="center">
  <img src="media/a3.png" alt="a3">
</div>

<br>

Embora o Power BI n√£o seja uma ferramenta dedicada para a modelagem de dados estruturados (como o pgModeler, por exemplo), ele √© capaz de realizar a manuten√ß√£o b√°sica. Veja na figura abaixo que o Power BI reconhece o modelo sem√¢ntico que estrutura as diferentes tabelas envolvidas, bem como as 3 rela√ß√µes "1-para-muitos" que conectam as chaves prim√°rias (em pedidos, produtos e clientes) √† tabela central "vendas".

<br>

<div align="center">
  <img src="media/a4.png" alt="a4">
</div>

<br>

## Pre√¢mbulo sobre Machine Learning

O aprendizado de m√°quina pode ser dividido em tr√™s categorias principais:

1. Aprendizado Supervisionado: no qual o algoritmo √© treinado com um conjunto de dados rotulados, ou seja, com entradas e sa√≠das conhecidas. O algoritmo utiliza esses dados  para  aprender  a  mapear  as  entradas  nas  sa√≠das  corretas.  Exemplos comuns incluem classifica√ß√£o de imagens e previs√£o de pre√ßos

2. Aprendizado N√£o Supervisionado: Aqui, o algoritmo √© treinado com um conjunto de dados n√£o rotulados, e seu objetivo √© encontrar padr√µes e estruturas subjacentes nos dados. Exemplos comuns incluem agrupamento e redu√ß√£o de dimensionalidade.

3. Aprendizado Por Refor√ßo: Neste tipo de aprendizado, o algoritmo, chamado de agente, aprende a tomar decis√µes com base em recompensas e puni√ß√µes. O agente interage com um ambiente e ajusta suas a√ß√µes para maximizar as recompensas a longo prazo. Exemplos comuns incluem jogos e rob√≥tica.

Neste projeto, ser√° realizado um processo de _clusteriza√ß√£o_, ou seja, **aprendizado n√£o supervisionado**. Os detalhes s√£o descritos abaixo

---

<h1 align="center">2. Segmenta√ß√£o de clientes com Machine Learning em linguagem Python</h1>

üîπInteraja com o [Dashboard online aqui](https://app.powerbi.com/groups/me/reports/cc233d4d-d9fe-475d-b275-ae1ea09235a1/ReportSection?experience=power-bi)

## Contexto

A segmenta√ß√£o de clientes √© o processo de dividir a base de clientes de uma empresa em grupos  distintos  com  base  em  caracter√≠sticas  comuns,  necessidades,  comportamentos  ou prefer√™ncias.  O  objetivo  da  segmenta√ß√£o  √©  entender  melhor  as  necessidades  e  desejos  de diferentes  grupos  de  clientes  e,  assim,adaptar  as  estrat√©gias  de  marketing,  comunica√ß√£o  e vendas para atender a essas necessidades de maneira mais eficaz e personalizada.

A segmenta√ß√£o pode ser feita com base em diversos crit√©rios, como:
1. Demogr√°ficos:  Idade,  sexo,  estado  civil,  renda,  ocupa√ß√£o,  n√≠vel  de  educa√ß√£o  e tamanho da fam√≠lia;
2. Geogr√°ficos:  Localiza√ß√£o,  clima,  densidade  populacional  e  fronteiras  pol√≠ticas  ou culturais;
3. Psicogr√°ficos: Estilo de vida, personalidade, valores, atitudes e interesses;
4. Comportamentais:  Padr√µes  de  compra,  frequ√™ncia  de  uso,  lealdade  √†  marca, prefer√™ncias e atitudes em rela√ß√£o a produtos e servi√ßos.

A segmenta√ß√£o de clientes pode beneficiar as empresas de v√°rias maneiras, incluindo:
1. Compreender melhor as necessidades e expectativas de diferentes grupos de clientes;
2. Desenvolver campanhas de marketing e comunica√ß√£o mais eficazes e personalizadas;
3. Identificar oportunidades de mercado e nichos ainda n√£o explorados;
4. Melhorar a satisfa√ß√£o e reten√ß√£o de clientes, oferecendo produtos e servi√ßos mais adequados √†s suas necessidades; e
4. Otimizar a aloca√ß√£o de recursos, concentrando-se nos segmentos de clientes mais lucrativos ou com maior potencial de crescimento.

As empresas podem utilizar t√©cnicas de an√°lise de dados e aprendizado de m√°quina para segmentar sua base de clientes de forma mais precisa e sofisticada, identificando padr√µes e rela√ß√µes complexas entre diferentes vari√°veis e comportamentos.

Nesta se√ß√£o, o aprendizado de m√°quina ser√° utilizado para segmentar clientes de acordo com determinadas caracter√≠sticas. O problema √© proposto sucintamente da seguinte forma:

Imagine que uma empresa tenha dados hist√≥ricos de clientes que fizeram compras de produtos ou servi√ßos. Os dados incluem,para cada cliente: idade, renda anual e uma pontua√ß√£o de gasto(poder de compra do cliente). A empresa gostaria de segmentar esses clientes em 3 grupos de acordo com similaridades a fim de personalizar as campanhas de Marketing. O gestor da √°rea de Marketing espera receber um relat√≥rio com os 3 segmentos e para cada segmento a m√©dia de idade, renda anual e pontua√ß√£o de gastos dos clientes.

---

Realizada uma an√°lise explorat√≥ria dos dados, inicia-se o aprendizado de m√°quina. √â necess√°rio, antes de mais nada, realizar o pr√©-processamento dos dados. O algoritmo de aprendizado n√£o-supervisionado KMeans (escolhido nesse caso devido ao problema de neg√≥cios, o qual envolve clusteriza√ß√£o) espera receber dados padronizados i.e. na mesma escala. Como n√£o iremos avaliar o modelo, n√£o haver√° divis√£o em grupos treino/teste. O processo √© sucintamente descrito no c√≥digo abaixo:

```
# Imports
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

df_dsa = pd.read_csv('recursos/dados/dados_clientes.csv') # Carrega os dados

df_dsa[['idade', 'renda_anual', 'pontuacao_gastos']].describe() # Resumo estat√≠stico

padronizador = StandardScaler() # Criando o padronizador dos dados

# Aplica o padronizador somente nas colunas de interesse
dados_padronizados = padronizador.fit_transform(df_dsa[['idade', 'renda_anual', 'pontuacao_gastos']])

k = 3 # Definindo o n√∫mero de clusters (k)

kmeans = KMeans (n_clusters = k) # o modelo √© criado

kmeans.fit(dados_padronizados) # treinamento do modelo com dados padronizados

df_dsa['cluster'] = kmeans.labels_ # atribu√≠mos os r√≥tulos dos clusters aos clientes
```

O n√∫mero de clusters _k_ √© o n√∫mero de agrupamentos que ser√£o realizados sobre os dados; h√° uma s√©rie de t√©cnicas para estimar o melhor valor de k, o que n√£o √© abordado aqui. A aplica√ß√£o do modelo resulta em uma nova coluna, "cluster", indicando a que grupo pertence determinado indiv√≠duo.

<br>

<div align="center">
  <img src="media/kmeans1.png" alt="a4">
</div>

<br>

Dentro de cada grupo, eu possuo a **maior** similaridade poss√≠vel.
Entre os grupos, eu possuo a **menor** similaridade poss√≠vel.

Em linhas gerais: o KMeans compara as dist√¢ncias entre cada vetor de dados (as linhas da matriz dados_padronizados), iterativamente, o que permite caracteriz√°-los.

Esta √© uma oportunidade fortuita para demonstrar a funcionalidade de integra√ß√£o de relat√≥rios PowerBI em ambiente Jupyter Notebook, realizada atrav√©s do pacote _powerbiclient_; este e outros recursos (como a publica√ß√£o online do relat√≥rio) podem ser utilizados atrav√©s do acesso √† Microsoft com uma conta de email institucional. No caso, estou utilizando a minha conta _alumni_ de ex-estudantes da USP. As etapas de constru√ß√£o podem ser verificadas no caderno "projeto_cluster.ipynb" deste reposit√≥rio. Uma das funcionalidades exibidas √© o QuickVisualize, o qual cria _internamente_ no caderno um relat√≥rio .pbix; 

```
from powerbiclient import QuickVisualize, get_dataset_config, Report
from powerbiclient.authentication import DeviceCodeLoginAuthentication

device_auth = DeviceCodeLoginAuthentication() # Define a autentica√ß√£o no Power BI Service

relatorio_PBI = QuickVisualize(get_dataset_config(df_dsa), auth = device_auth) # Cria o relat√≥rio no Power BI
```

o PowerBI tenta organizar as informa√ß√µes consideradas mais importantes em uma estrutura de visualiza√ß√µes, geralmente acompanhadas de uma narrativa inteligente. O resultado do c√≥digo acima √© a visualiza√ß√£o abaixo:

<div align="center">
  <img src="media/pbixcliente.gif" alt="a1">
</div>

<br>

Este recurso, embora interessante para uma r√°pida visualiza√ß√£o, como o nome diz, n√£o necessariamente gera informa√ß√µes relevantes automaticamente (o que pode vir a mudar no futuro recente com a implementa√ß√£o do _Copilot_ em ferramentas como o PowerBI): repare, por exemplo, que o comportamento autom√°tico do PowerBI ao lidar com vari√°veis num√©ricas √© realizar a soma (note os t√≠tulos das visualiza√ß√µes, "sum of renda_anual by idade", "sum of id by idade", etc), o que n√£o faz sentido dependendo do contexto, como no caso da idade. Todas estas informa√ß√µes devem ser verificadas e retrabalhadas quando necess√°rio. O "quick_visualizer", no entanto, ao menos da um pontap√© inicial e pode vir a ser √∫til em uma primeira inspe√ß√£o.

Neste caso espec√≠fico, √© vantajoso retrabalhar as visualiza√ß√µes e a formata√ß√£o para melhor atender √†s perguntas realizadas no in√≠cio da se√ß√£o. A grande vantagem do QuickVisualize, neste caso, √© que podemos publicar o relat√≥rio na nuvem e baixar um arquivo pbix j√° com todas as informa√ß√µes engatilhadas. N√£o √© necess√°rio come√ßar o trabalho do zero. Realizadas as modifica√ß√µes, o resultado final pode ser visualizado no relat√≥rio abaixo:

<div align="center">
  <img src="media/relatorio.png" alt="a1">
</div>

<br>

Agora, √© mais f√°cil extrair as informa√ß√µes mais relevantes de toda esta an√°lise:

1. O cabe√ßalho exibe as m√©tricas globais;
2. A m√©dia de pontua√ß√£o de gastos por segmento indica que o segmento 1 deve receber uma aten√ß√£o maior pela equipe de marketing (s√£o aqueles que mais adquirem produtos/servi√ßos desta empresa).
3. O total de clientes por segmento √© balanceado, o que √© esperado em uma tarefa de machine learning para segmenta√ß√£o.
4. A m√©dia de rendimento anual por segmento indica que o grupo 0 √© o que possui maior renda; √© interessante notar portanto que uma maior renda n√£o se traduz em uma maior pontua√ß√£o de gastos.
5. As m√©dias de idade para os segmentos 0 e 1 s√£o quase coincidentes: 53 e 54 anos. O segmento 2 √© o que mais destoa neste quesito, com m√©dia de 27 anos.

Esta an√°lise pode ser devolvida agora ao departamento de marketing, o qual poder√° refinar suas campanhas utilizando como alvo os 3 clusters analisados aqui. Cada campanha, espera-se, ser√° customizada para as caracter√≠sticas de cada grupo.

---

<h1 align="center">3. Detec√ß√£o de anomalias com Machine Learning em linguagem R</h1>

üîπInteraja com o [Dashboard online aqui](https://app.powerbi.com/groups/me/reports/6d58dbbd-c9f6-43cb-b689-8446c3655571/ReportSection?experience=power-bi)

A detec√ß√£o de anomalias, tamb√©m conhecida como detec√ß√£o de outliers, √© uma t√©cnica em  Machine  Learning  e Estat√≠stica  que  visa  identificar  padr√µes  incomuns,  inesperados  ou an√¥malos nos dados. Esses padr√µes podem ser diferentes das observa√ß√µes normais de v√°rias maneiras,  como  magnitude,  frequ√™ncia  ou  comportamento.  A  detec√ß√£o  de  anomalias  √© importante porque as anomalias podem indicar problemas, erros, falhas, fraudes ou atividades maliciosas e, em muitos casos, √© crucial identificar e analisar esses eventos an√¥malos para tomar decis√µes informadas e apropriadas.

<details>
<summary>Contexto</summary>

Existem v√°rias abordagens para detectar anomalias em Machine Learning, algumas das quais incluem:

1. **M√©todos Estat√≠sticos**: baseiam-se na an√°lise estat√≠stica dos dados, como testes de hip√≥teses, distribui√ß√µes de probabilidade e medidas de dispers√£o (por exemplo, desvio padr√£o e intervalos interquartis). Observa√ß√µes que est√£o significativamente distantes da m√©dia ou fora dos intervalos esperados s√£o consideradas an√¥malas.

2. **Aprendizado Supervisionado**:  nesta  abordagem,  um  modelo  de  Machine  Learning  √© treinado usando um conjunto de dados rotulado, que inclui exemplos de observa√ß√µes normais e an√¥malas. O modelo aprende a distinguir entre as duas classes e, em seguida, pode ser usado para  classificar  novas  observa√ß√µes  como  normais  ou  an√¥malas.

3. **Aprendizado N√£o Supervisionado**: neste caso, os algoritmos de Machine Learning s√£o usados para analisar dados n√£o rotulados e identificar padr√µes ou agrupamentos naturais neles. As anomalias s√£o identificadas como pontos de dados que n√£o se encaixam bem em nenhum desses agrupamentos ou que est√£o significativamente distantes de outros pontos de dados. Alguns exemplos de algoritmos de aprendizado n√£o supervisionado usados para detec√ß√£o de anomalias incluem clustering (por exemplo, K-means) e t√©cnicas de redu√ß√£o de dimensionalidade (por exemplo, PCA).

4. **Aprendizado Semi-Supervisionado**: esta abordagem combina elementos de aprendizado supervisionado e n√£o supervisionado. Os algoritmos s√£o treinados em um conjunto de dados parcialmente rotulado, que cont√©m exemplos de observa√ß√µes normais e um pequeno n√∫mero de  exemplos an√¥malos. O  modelo aprende a distinguir entre as classes e identificar novas anomalias com base nos padr√µes aprendidos.

5. **M√©todos Baseados em Densidade**: esses m√©todos identificam anomalias como pontos de dados que est√£o localizados em √°reas de baixa densidade do espa√ßo de recursos (atributos). Um exemplo popular de algoritmo de detec√ß√£o de anomalias baseado em densidade √© o DBSCAN (_Density-Based Spatial Clustering of Applications with Noise_)

6. **M√©todos Baseados em Vizinhan√ßa**: esses m√©todos comparam a dist√¢ncia ou similaridade entre pontos de dados e seus vizinhos para identificar anomalias. Os pontos de dados que t√™m vizinhos significativamente diferentes de si mesmos s√£o considerados an√¥malos. Exemplos de algoritmos que empregam essa abordagem incluem o k-NN (k-Nearest Neighbors) e o LOF (Local Outlier Factor). 

A escolha do m√©todo mais adequado para detec√ß√£o de anomalias depende do contexto, da natureza dos dados, do conhecimento t√©cnico do profissional de an√°lise e do tipo de problema que desejamos resolver.

</details>

---

O problema proposto √© descrito a seguir:
- Imagine que uma empresa da √°rea financeira tenha dados hist√≥ricos de clientes com duas transa√ß√µes financeiras (aqui chamadas de ‚Äútransacao1‚Äù e ‚Äútransacao2‚Äù). Os gestores acreditam que algumas dessas transa√ß√µes possam ser fraudulentas e gostariam de identificar as eventuais anomalias. Os gestores n√£o fazem ideia do que seria uma anomalia e pediram sua ajuda para encontrar uma solu√ß√£o. De fato, eles n√£o sabem se anomalias realmente ocorreram. Usando dados fict√≠cios usaremos Machine Learning para agrupar os dados de transa√ß√µes financeiras dos clientes e ent√£o detectar e definir as anomalias (se existirem). O resultado deve ser entregue no formato visual atrav√©s de gr√°ficos no Power BI.

A linguagem R ser√° util em duas frentes nesse caso: para executar o algoritmo de detec√ß√£o de anomalia e para gerar uma visualiza√ß√£o em box-plot, a qual n√£o existe de forma nativa no Power BI (o que, convenhamos, √© ligeiramente surpreendente). Para este projeto, utilizamos R e Rtools na IDE RStudio:

<div align="center">
  <img src="media/rstudio.png" alt="r">
</div>

<br>

- Os pacotes _tidyverse, dplyr_ e _readr_ s√£o utilizados na manipula√ß√£o dos dados;
- _solitude_ traz o algoritmo de machine learning para a detec√ß√£o de anomalias; e
- _ggplot2_ √©, verdade seja dita, seguramente um dos melhores pacotes para visualiza√ß√£o de dados atualmente. O rev√©s est√° na curva de aprendizado relativamente √≠ngrime.

Ao visualizar o conjunto de dados, fica claro que √© necess√°ria novamente a escolha por um algoritmo n√£o-supervisionado: n√£o h√° dados hist√≥ricos ou "verdade de campo" para balizar o treinamento. O aprendizado ser√° realizado _da capo_, <br>
_in loco_, <br>
_allegro, ma non troppo_..

O algoritmo vai buscar padr√µes no conjunto de dados e posteriormente buscar aquilo que foge destes padr√µes. N√£o h√° dados de sa√≠da (eu ainda n√£o sei o que √© anomalia), apenas os dados de entrada. Dentro do pacote _solitude_, podemos utilizar o algoritmo Isolation Forest.

O treinamento e aplica√ß√£o do algoritmo ao nosso conjunto pr√©vio de dados gera um par√¢metro "anomaly score". Quanto maior o anomaly score, maior a chance do registro ser uma anomalia.

<div align="center">
  <img src="media/anomaly_plot.png" alt="r">
</div>

<br>

Observa-se que a vasta maioria dos registros possui um score < 0.60; podemos supor que estes registros de transa√ß√µes n√£o configuram fraudes. Vamos definir como regra que um anomaly score acima de 0.62 √© uma anomalia. Podemos agora aplicar um filtro sobre os dados iniciais e utilizar o _ggplot_ para construir um gr√°fico de dispers√£o entre as transa√ß√µes do tipo 1 e 2, discriminando aqueles que passam pelo filtro (em azul) e aqueles que n√£o passam (em vermelho):

<div align="center">
  <img src="media/ggplot.png" alt="r">
</div>

<br>

A tabela anomalias_hist√≥rico (verifique no arquivo Lab8.R) guarda as transa√ß√µes que n√£o passaram pelo filtro aplicado pelo algoritmo. <br>
O modelo criado pode agora ser utilizado para a verifica√ß√£o de fraude em novos conjuntos de dados. Nota-se que o modelo funciona, mas h√° definitivamente espa√ßo para refinamento: as transa√ß√µes nas bordas do plot definitivamente fogem ao padr√£o, mas o modelo n√£o capture todos (e.g. note as transa√ß√µes em azul no canto superior direito); ao mesmo tempo, o modelo identifica como fraudulentas muitas transa√ß√µes na regi√£o central-inferior e central-esquerda, pr√≥ximas ao aglomerado, o que n√£o necessariamente √© apropriado. O ajuste do algoritmo de forma iterativa permitir√° uma classifica√ß√£o cada vez mais criteriosa.

<div align="center">
  <img src="media/ggplot2.png" alt="r">
</div>

<br>

Podemos visualizar a tabela de previs√£o dos novos dados em formato boxplot. Isto √© particularmente interessante para explicitar a presen√ßa de outliers. Note, destacado em verde, que as transa√ß√µes ali representadas claramente configuram pares que destoam completamente dos padr√µes exibidos naquele conjunto de dados. Esta informa√ß√£o poderia ser utilizada para alterar o valor de score que escolhemos como filtro. Talvez 0.62 tenha sido um filtro muito agressivo, e algo superior a 0.63/0.64 seja uma escolha mais criteriosa. Um novo modelo pode ser treinado e o processo refeito para verifica√ß√£o.

<div align="center">
  <img src="media/boxplot.png" alt="r">
</div>

<br>

Neste momento, podemos optar por importar esta visualiza√ß√£o para o Power BI, uma vez que l√° n√£o conseguimos (ainda) construir boxplots. A visualiza√ß√£o "R Script Visual" requer os atributos que est√£o sendo utilizados _e_ o c√≥digo-fonte escrito em linguagem R para que a visualiza√ß√£o seja processada. Cumpridas estas etapas, podemos seguir a customiza√ß√£o do relat√≥rio pbix como de praxe.

<div align="center">
  <img src="media/transfer_powerbi.gif" alt="r1">
</div>

<br>

Podemos agora fazer uma √∫ltima customiza√ß√£o do nosso dashboard e construir um relat√≥rio final. A grande vantagem da integra√ß√£o entre o visual criado com o pacote ggplot no RStudio e a posterior exporta√ß√£o √© que podemos agora usufruir da interatividade usual para visualiza√ß√µes nativas do PowerBI. Observe abaixo:

<div align="center">
  <img src="media/transfer_powerbi2.gif" alt="r2">
</div>

<br>

O que antes era um gr√°fico est√°tico no RStudio agora interage din√¢micamente com as outras visualiza√ß√µes do PowerBI. Esta funcionalidade √© extremamente poderosa, ainda mais quando utilizada em conjunto com uma biblioteca do calibre do ggplot.

---

<h1 align="center">4. Intelig√™ncia Artificial e S√©ries Temporais com Power BI</h1>

üîπInteraja com o [Dashboard online aqui](https://app.powerbi.com/groups/me/reports/dd70e51d-80bb-47c6-b45b-ebb6bc73c39f/ReportSection?experience=power-bi)

<details>
<summary>Contexto</summary>

Existem   v√°rias   t√©cnicas   de   an√°lise   de  s√©ries   temporais,   que   v√£o   desde modelos estat√≠sticos cl√°ssicos a abordagens mais modernas de Aprendizado  de M√°quina e Intelig√™ncia Artificial. Aqui est√£o algumas das t√©cnicas mais comuns:

1. **An√°lise  de Tend√™ncias**:  Esta  √© uma  das  t√©cnicas  mais  simples,  onde  se  procura  uma tend√™ncia persistente ao longo do tempo, como por exemplo um aumento constante ou uma queda nos dados;

2. **M√©dias M√≥veis e Suaviza√ß√£o Exponencial**: Estas s√£o t√©cnicas para remover o "ru√≠do" de uma  s√©rie  temporal,  fazendo  a  m√©dia  de  pontos  de  dados  em  um  determinado  n√∫mero  de per√≠odos de tempo;

3. **Decomposi√ß√£o**: Esta t√©cnica envolve a separa√ß√£o da s√©rie temporal em componentes de tend√™ncia, sazonalidade e res√≠duos (o que resta depois de remover a tend√™ncia e a sazonalidade);

4. **Modelos Autorregressivos (AR)**: Em  um  modelo  AR,  o  valor  de  uma  vari√°vel em um determinado momento √© suposto ser uma fun√ß√£o linear dos valores anteriores;

5. **Modelos de M√©dias M√≥veis (MA)**: J√° em um modelo  MA, o valor de uma vari√°vel em um determinado  momento  √©  suposto  ser  uma  fun√ß√£o  linear  dos  erros  de  previs√£o  dos  pontos anteriores;

6. **Modelos ARIMA (Autoregressive Integrated Moving Average)**: Estes combinam modelos AR e MA e tamb√©m incluem um termo de "diferencia√ß√£o" para tornar a s√©rie  temporal estacion√°ria;

7. **Modelos de Aprendizado de M√°quina (Machine Learning)**: Modelos de aprendizado de m√°quina  como  redes  neurais,  SVMs,  florestas  aleat√≥rias,  gradient  boosting, etc., podem ser usados para modelar s√©ries temporais. Especificamente, redes neurais como LSTMs e GRUs s√£o particularmente  adequadas  para  s√©ries  temporais por causa de sua capacidade de "lembrar" valores passados;

8. **Modelos de Aprendizado Profundo (Deep Learning)**: Redes Neurais Recorrentes (RNNs) e  suas  variantes  como  Long  Short  Term  Memory  (LSTM)  e  Gated  Recurrent Units (GRUs) s√£o amplamente  usadas  para  modelagem  de s√©ries   temporais. Mais  recentemente, modelos baseados em Transformers est√£o sendo aplicados √† an√°lise de s√©ries temporais. A escolha da t√©cnica apropriada depende do problema espec√≠fico da s√©rie temporal, da natureza dos dados, da disponibilidade de recursos computacionais e de outros fatores.

O Power BI n√£o √© uma ferramenta para an√°lise de s√©ries temporais, mas oferece alguns recursos simples que podem ser utilizados para uma an√°lise geral. Ser√£o aplicas duas an√°lises: uma preditiva e uma de detec√ß√£o de anomalias, no contexto de engenharia de produ√ß√£o. Este setor fornece ao analista uma tabela contendo os atributos "per√≠odo" (data), "turno", o "range de idade dos funcion√°rios" e o "total de unidades produzidas" em uma determinada ind√∫stria.

√â importante delimitar alguns conceitos, antes de mais nada:

- **Estacionaridade**:  Uma  s√©rie  temporal  √©  dita  estacion√°ria  se  suas  propriedades estat√≠sticas, como m√©dia, vari√¢ncia e autocorrela√ß√£o, s√£o constantes ao longo do tempo. Isso significa  que,  independentemente  do  ponto  espec√≠fico  do  tempo  que  voc√™  selecionar,  as caracter√≠sticas estat√≠sticas da s√©rie temporal ser√£o as mesmas. Esta √© uma suposi√ß√£o importante em muitos modelos de s√©ries temporais, porque simplifica as previs√µes. No entanto, muitas s√©ries temporais do mundo real n√£o s√£o estacion√°rias, mas podem ser transformadas em s√©ries estacion√°rias atrav√©s de m√©todos como a diferencia√ß√£o.

- **Tend√™ncia**: A tend√™ncia refere-se a um padr√£o de longo prazo na s√©rie temporal que mostra uma dire√ß√£o geral. Por exemplo, se as vendas de um produto est√£o consistentemente aumentando ao longo do tempo, diz-se que h√° uma tend√™ncia de alta. Por outro lado, se a temperatura de uma cidade est√° consistentemente diminuindo ao longo do tempo, h√° uma tend√™ncia de baixa. A tend√™ncia pode ser linear (ou seja, a s√©rie aumenta ou diminui a uma taxa constante) ou n√£o-linear.

- **Sazonalidade**: A sazonalidade refere-se a padr√µes que se repetem em intervalos fixos de tempo. Por exemplo, as vendas de sorvete podem ser mais altas no ver√£o e mais baixas no inverno  todos  os  anos,  o  que  √©  um  exemplo  de  sazonalidade  anual.  Da  mesma  forma, a quantidade de tr√°fego da web pode ser mais alta durante a semana e mais baixa nos fins de semana, o  que  √©  um  exemplo  de  sazonalidade  semanal.  Ajustar  a  sazonalidade  pode  ser importante para fazer previs√µes precisas, especialmente para neg√≥cios ou fen√¥menos que s√£o fortemente influenciados por fatores sazonais.

A  identifica√ß√£o  e  o  ajuste  da  estacionaridade,  tend√™ncia  e  sazonalidade  podem  ser essenciais  para  a  modelagem  efetiva  de  s√©ries  temporais  e  para  a  realiza√ß√£o  de  previs√µes precisas.

</details>

## Constru√ß√£o do Dashboard

A detec√ß√£o de outliers √© a primeira ferramenta de intelig√™ncia artificial implementada no Power BI (veja abaixo). Essa se√ß√£o deve ser expandida nas pr√≥ximas vers√µes do programa. Podemos customizar o intervalo "normal" modificando o n√≠vel de Confidencialidade (%): quanto maior, mais agressiva a detec√ß√£o de observa√ß√µes que est√£o "fora da m√©dia".

<div align="center">
  <img src="media/anomaly.gif" alt="a22">
</div>

Al√©m disso, analisando a m√©dia do total de unidades produzidas ao longo do tempo, podemos nos perguntar se √© poss√≠vel prever como essa produ√ß√£o se conduzir√° no futuro. Esta √© a an√°lise de forecasting, visualizada no gr√°fico inferior do dashboard abaixo, j√° formatado para o resultado final. Esta an√°lise preditiva tamb√©m pode ser customizada: modificando-se o comprimento da previs√£o (quanto maior, mais imprecisa √© a ferramenta, √© claro), ou adicionando efeitos de sazonalidade. Observe que se filtrarmos apenas a faixa et√°ria de "65 anos e acima", o modelo prev√™ uma queda acentuada na produ√ß√£o de unidades, uma vez que esse grupo possui a pior performance dentre todas as faixas de idade.

<div align="center">
  <img src="media/forecasting.gif" alt="r2">
</div>

Outras funcionalidades s√£o √∫teis aqui, principalmente para gr√°ficos de linha, como as op√ß√µes de "drill up" e "drill down", as quais permitem agrupar os valores em diferentes n√≠veis da hierarquia de data e.g. m√©dias anuais, trimestrais, mensais e assim por diante.

![Abhinandan Trilokia](https://raw.githubusercontent.com/Trilokia/Trilokia/379277808c61ef204768a61bbc5d25bc7798ccf1/bottom_header.svg)
